{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据路径\n",
    "data_dir = 'D:\\FDU\\Course\\DeepLearning\\midterm\\CUB_200_2011\\CUB_200_2011'\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "\n",
    "# 读取划分文件\n",
    "split_data = pd.read_csv(os.path.join(data_dir, 'train_test_split.txt'), \n",
    "                         delim_whitespace=True, header=None, names=['id', 'train_flag'])\n",
    "\n",
    "# 设置图像变换\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载全部图像\n",
    "full_dataset = ImageFolder(root=images_dir, transform=transformations)\n",
    "\n",
    "# 分割训练集和测试集\n",
    "train_idx = split_data[split_data['train_flag'] == 1]['id'].values - 1\n",
    "test_idx = split_data[split_data['train_flag'] == 0]['id'].values - 1\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "    accuracy = correct.double() / len(loader.dataset)\n",
    "    return running_loss / len(loader.dataset), accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 5.507534643312594, Test Loss: 5.403356584549608, Test Accuracy: 0.013462202278218847\n",
      "Epoch 2, Train Loss: 5.197170884441367, Test Loss: 5.068711027343561, Test Accuracy: 0.02744218156713842\n",
      "Epoch 3, Train Loss: 4.876232302503105, Test Loss: 4.886903369101648, Test Accuracy: 0.03296513634794615\n",
      "Epoch 4, Train Loss: 4.625261890359191, Test Loss: 4.7269451504622735, Test Accuracy: 0.05298584742837418\n",
      "Epoch 5, Train Loss: 4.4285221370331715, Test Loss: 4.665962403586786, Test Accuracy: 0.057128063513979976\n",
      "Epoch 6, Train Loss: 4.275384864450734, Test Loss: 4.43161507709544, Test Accuracy: 0.06506731101139109\n",
      "Epoch 7, Train Loss: 4.095021944345137, Test Loss: 4.431640689028186, Test Accuracy: 0.07783914394200897\n",
      "Epoch 8, Train Loss: 3.9226418103143934, Test Loss: 4.4770332278158484, Test Accuracy: 0.0700724887814981\n",
      "Epoch 9, Train Loss: 3.769778832301005, Test Loss: 4.136719866131436, Test Accuracy: 0.10372799447704521\n",
      "Epoch 10, Train Loss: 3.5712448138573345, Test Loss: 4.043028972212265, Test Accuracy: 0.11546427338626164\n",
      "Epoch 11, Train Loss: 3.4239266274330973, Test Loss: 4.123492484509143, Test Accuracy: 0.11339316534345875\n",
      "Epoch 12, Train Loss: 3.230911331094023, Test Loss: 4.338157210466901, Test Accuracy: 0.1070072488781498\n",
      "Epoch 13, Train Loss: 3.095466247907988, Test Loss: 4.032925363651917, Test Accuracy: 0.11977908180876769\n",
      "Epoch 14, Train Loss: 2.943602804665093, Test Loss: 3.7404764581640135, Test Accuracy: 0.1567138419054194\n",
      "Epoch 15, Train Loss: 2.72602558422375, Test Loss: 3.983457194635446, Test Accuracy: 0.15464273386261648\n",
      "Epoch 16, Train Loss: 2.5586212113335565, Test Loss: 3.9912166422632263, Test Accuracy: 0.13945460821539524\n",
      "Epoch 17, Train Loss: 2.3685276994396536, Test Loss: 4.239269342511368, Test Accuracy: 0.1637901277183293\n",
      "Epoch 18, Train Loss: 2.1664935057267454, Test Loss: 4.021178870930275, Test Accuracy: 0.1729375215740421\n",
      "Epoch 19, Train Loss: 1.9538116161529724, Test Loss: 3.7475168309131077, Test Accuracy: 0.18967897825336555\n",
      "Epoch 20, Train Loss: 1.7229695292286051, Test Loss: 3.8317233112955407, Test Accuracy: 0.18898860890576458\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载预训练的ResNet-18模型\n",
    "model = resnet18(pretrained=False)\n",
    "\n",
    "# 修改输出层\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "\n",
    "# 定义设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 为新的输出层设置高学习率，其他层设置低学习率\n",
    "params_to_update = []\n",
    "params_names = []\n",
    "\n",
    "# 只对非全连接层参数应用低学习率\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        if name not in ['fc.weight', 'fc.bias']:\n",
    "            params_to_update.append(param)\n",
    "            params_names.append(name)\n",
    "\n",
    "\n",
    "# 初始化TensorBoard\n",
    "writer = SummaryWriter('runs/birds_experiment_')\n",
    "\n",
    "# 使用两个参数组\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model.fc.parameters(), 'lr': 0.01},  # 高学习率仅适用于全连接层\n",
    "    {'params': params_to_update, 'lr': 0.001}       # 低学习率适用于其余层\n",
    "], momentum=0.9)\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_accuracy = validate(model, test_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Test', test_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Test', test_accuracy, epoch)\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
